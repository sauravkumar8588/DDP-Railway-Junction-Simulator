{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d91e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed: 62 nodes, 73 edges\n",
      "Loaded 4 OD pairs (requests)\n",
      "OD 2->58: found 0 feasible routes\n",
      "OD 3->58: found 0 feasible routes\n",
      "OD 59->1: found 0 feasible routes\n",
      "OD 59->3: found 0 feasible routes\n",
      "Wrote feasible routes to feasible_routes.txt\n",
      "Iteration complete: scheduled_count=0\n",
      "Scheduling finished; total trains scheduled: 0\n",
      "No trains scheduled. Exiting.\n",
      "Wrote occupancy log to occupancy_log.csv (records: 0)\n",
      "Maximum number of trains scheduled safely (within 1 hour starts): 0\n",
      "Saving animation to MP4 (this may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP4 save failed: unknown file extension: .mp4\n",
      "Saving animation to GIF (fallback)...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "route_schedule_and_animate.py\n",
    "\n",
    "Builds graph from Book-(Sheet1).csv (uses 'adjacent_connected_node(s)' column),\n",
    "reads OD requests from source_destination.csv, finds obtuse-turn-only routes,\n",
    "schedules trains with safety rules, writes feasible routes + occupancy CSV,\n",
    "and saves an animation (MP4 or GIF).\n",
    "\n",
    "Author: ChatGPT (GPT-5 Thinking mini)\n",
    "\"\"\"\n",
    "\n",
    "import os, csv, math, heapq, random\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# ----------------------------\n",
    "# USER PARAMETERS (tweak if needed)\n",
    "# ----------------------------\n",
    "NODES_CSV = \"Book-(Sheet1).csv\"           # node file (must include nodes,x,y,adjacent_connected_node(s))\n",
    "OD_CSV = \"source_destination.csv\"         # must include source,destination (column names flexible)\n",
    "OUT_ROUTES = \"feasible_routes.txt\"\n",
    "OUT_OCC = \"occupancy_log.csv\"\n",
    "OUT_ANIM_MP4 = \"train_schedule.mp4\"\n",
    "OUT_ANIM_GIF = \"train_schedule.gif\"\n",
    "\n",
    "# physical & scheduling\n",
    "SPEED_MPS = 8.0               # 8 m/s\n",
    "HEADWAY_S = 600               # 10 minutes\n",
    "SAFE_DISTANCE_M = 500.0       # 500 meters separation alternative\n",
    "TRAIN_LENGTH_M = 400.0        # train length (for tail clear)\n",
    "NODE_FREE_NORMAL_S = 120      # 2 minutes after tail clears\n",
    "NODE_FREE_SWITCH_S = 300      # 5 minutes after tail clears (for degree >= 3)\n",
    "MAX_PATHS_PER_OD = 30         # limit to avoid combinatorial explosion\n",
    "MAX_HOPS = 20                 # max hops for route search\n",
    "MAX_TRAINS_CAP = 500          # hard maximum scheduled trains\n",
    "START_TIME = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
    "START_WINDOW_SECONDS = 3600   # allow train starts within first 1 hour\n",
    "ANIM_DURATION_SECONDS = 60.0  # playback length (seconds)\n",
    "FPS = 20\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def dist_m(p, q):\n",
    "    return math.hypot(p[0] - q[0], p[1] - q[1])\n",
    "\n",
    "def angle_between(prev, cur, nxt):\n",
    "    \"\"\"Angle in degrees between vector (cur - prev) and (nxt - cur)\"\"\"\n",
    "    v1 = (cur[0] - prev[0], cur[1] - prev[1])\n",
    "    v2 = (nxt[0] - cur[0], nxt[1] - cur[1])\n",
    "    n1 = math.hypot(v1[0], v1[1])\n",
    "    n2 = math.hypot(v2[0], v2[1])\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return 180.0\n",
    "    dot = (v1[0]*v2[0] + v1[1]*v2[1]) / (n1*n2)\n",
    "    dot = max(-1.0, min(1.0, dot))\n",
    "    return math.degrees(math.acos(dot))\n",
    "\n",
    "# ----------------------------\n",
    "# Load nodes CSV & build graph\n",
    "# ----------------------------\n",
    "if not os.path.exists(NODES_CSV):\n",
    "    raise FileNotFoundError(f\"{NODES_CSV} not found. Put it in the working directory.\")\n",
    "\n",
    "nodes = {}\n",
    "with open(NODES_CSV, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for r in reader:\n",
    "        node = str(r.get('nodes') or r.get('id') or r.get('node')).strip()\n",
    "        if node == \"\":\n",
    "            continue\n",
    "        x = float(r.get('x') or r.get('lon') or r.get('X') or 0.0)\n",
    "        y = float(r.get('y') or r.get('lat') or r.get('Y') or 0.0)\n",
    "        adj = r.get('adjacent_connected_node(s)') or r.get('adjacent') or r.get('adj') or \"\"\n",
    "        nodes[node] = {'x': x, 'y': y, 'adj': adj}\n",
    "\n",
    "G = nx.Graph()\n",
    "for n, v in nodes.items():\n",
    "    G.add_node(n, x=v['x'], y=v['y'])\n",
    "\n",
    "# Build edges from adjacency column (supports comma/semicolon/space separated)\n",
    "for n, v in nodes.items():\n",
    "    raw = (v.get('adj') or \"\").strip()\n",
    "    if not raw:\n",
    "        continue\n",
    "    san = raw.replace('\"', '').replace(\"'\", \"\")\n",
    "    sep = ',' if ',' in san else ';' if ';' in san else ' '\n",
    "    for tok in [t.strip() for t in san.split(sep) if t.strip()]:\n",
    "        if tok not in nodes:\n",
    "            # placeholder node at 0,0 if somehow referenced\n",
    "            nodes.setdefault(tok, {'x':0.0, 'y':0.0, 'adj':\"\"})\n",
    "            if tok not in G:\n",
    "                G.add_node(tok, x=0.0, y=0.0)\n",
    "        if not G.has_edge(n, tok):\n",
    "            lm = dist_m((nodes[n]['x'], nodes[n]['y']), (nodes[tok]['x'], nodes[tok]['y']))\n",
    "            G.add_edge(n, tok, length_m=lm)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Graph constructed: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# ----------------------------\n",
    "# Read OD requests\n",
    "# ----------------------------\n",
    "if not os.path.exists(OD_CSV):\n",
    "    raise FileNotFoundError(f\"{OD_CSV} not found. Provide source_destination.csv in working directory.\")\n",
    "\n",
    "od_list = []\n",
    "with open(OD_CSV, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    # try common headers\n",
    "    for r in reader:\n",
    "        s = str(r.get('source') or r.get('from') or r.get('src') or r.get('origin') or '').strip()\n",
    "        d = str(r.get('destination') or r.get('to') or r.get('dst') or r.get('dest') or '').strip()\n",
    "        if s == \"\" or d == \"\":\n",
    "            # try first two columns if headers unknown\n",
    "            keys = list(r.keys())\n",
    "            if len(keys) >= 2:\n",
    "                s = str(r[keys[0]]).strip(); d = str(r[keys[1]]).strip()\n",
    "        if s and d:\n",
    "            if s not in G or d not in G:\n",
    "                if DEBUG:\n",
    "                    print(f\"OD pair {s}->{d} references unknown node; skipping.\")\n",
    "                continue\n",
    "            od_list.append((s,d))\n",
    "if not od_list:\n",
    "    raise RuntimeError(\"No valid OD pairs found in source_destination.csv\")\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Loaded {len(od_list)} OD pairs (requests)\")\n",
    "\n",
    "# ----------------------------\n",
    "# Feasible routes finder (all simple paths with obtuse-turn constraint)\n",
    "# We'll do a DFS but cap total paths per OD and max hops to avoid explosion.\n",
    "# ----------------------------\n",
    "def find_feasible_routes(G, source, target, max_paths=MAX_PATHS_PER_OD, max_hops=MAX_HOPS, angle_min_deg=90.0):\n",
    "    routes = []\n",
    "    stack = [(source, [source])]\n",
    "    while stack and len(routes) < max_paths:\n",
    "        cur, path = stack.pop()\n",
    "        if len(path) > max_hops:\n",
    "            continue\n",
    "        if cur == target:\n",
    "            routes.append(list(path))\n",
    "            continue\n",
    "        # neighbors sorted by increasing edge length (heuristic for short routes first)\n",
    "        neighbors = sorted(G.neighbors(cur), key=lambda nb: G.edges[cur, nb]['length_m'])\n",
    "        for nb in neighbors:\n",
    "            if nb in path:\n",
    "                continue\n",
    "            if len(path) >= 2:\n",
    "                prev = path[-2]\n",
    "                prev_coord = (G.nodes[prev]['x'], G.nodes[prev]['y'])\n",
    "                cur_coord = (G.nodes[cur]['x'], G.nodes[cur]['y'])\n",
    "                nb_coord = (G.nodes[nb]['x'], G.nodes[nb]['y'])\n",
    "                ang = angle_between(prev_coord, cur_coord, nb_coord)\n",
    "                # require non-acute: angle >= angle_min_deg\n",
    "                if not (ang + 1e-9 >= angle_min_deg):\n",
    "                    continue\n",
    "            stack.append((nb, path + [nb]))\n",
    "    return routes\n",
    "\n",
    "# compute feasible routes for each OD\n",
    "feasible_routes = {}\n",
    "for s,d in od_list:\n",
    "    routes = find_feasible_routes(G, s, d, max_paths=MAX_PATHS_PER_OD, max_hops=MAX_HOPS, angle_min_deg=90.0)\n",
    "    feasible_routes[(s,d)] = routes\n",
    "    if DEBUG:\n",
    "        print(f\"OD {s}->{d}: found {len(routes)} feasible routes\")\n",
    "\n",
    "# write feasible routes to text for inspection\n",
    "with open(OUT_ROUTES, 'w', encoding='utf-8') as f:\n",
    "    for (s,d), rlist in feasible_routes.items():\n",
    "        f.write(f\"{s} -> {d} : {len(rlist)} routes\\n\")\n",
    "        for r in rlist:\n",
    "            f.write(\"  \" + \" -> \".join(r) + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "if DEBUG:\n",
    "    print(f\"Wrote feasible routes to {OUT_ROUTES}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Scheduling helpers & occupancy structures\n",
    "# ----------------------------\n",
    "def canonical_seg(u, v):\n",
    "    return tuple(sorted((u, v)))\n",
    "\n",
    "# occupancy per-segment: seg_id -> dict {+1: [ (entry, tail_clear) , ... ], -1: [...]}\n",
    "segment_occupancy = defaultdict(lambda: {+1: [], -1: []})\n",
    "# node occupancy: node -> list of (start_busy, end_busy)\n",
    "node_occupancy = defaultdict(list)\n",
    "\n",
    "# helper: compute node free buffer depending on degree\n",
    "def node_free_buffer(node):\n",
    "    deg = G.degree(node)\n",
    "    return NODE_FREE_SWITCH_S if deg >= 3 else NODE_FREE_NORMAL_S\n",
    "\n",
    "# check segment placement\n",
    "def can_place_segment(seg, direction, entry_front, tail_clear):\n",
    "    # same direction: allow if either entry_front >= existing_entry + HEADWAY_S OR distance sep >= SAFE_DISTANCE_M\n",
    "    same_list = segment_occupancy[seg][direction]\n",
    "    for (e1, e2) in same_list:\n",
    "        delta_sec = (entry_front - e1).total_seconds()\n",
    "        if delta_sec < 0:\n",
    "            # new start before an existing start -- this algorithm schedules increasing time\n",
    "            # treat as potential conflict if intervals overlap\n",
    "            if not (tail_clear <= e1):\n",
    "                return False\n",
    "            else:\n",
    "                continue\n",
    "        # check headway time\n",
    "        if delta_sec >= HEADWAY_S:\n",
    "            continue\n",
    "        # else check spatial separation at new start time\n",
    "        dist_sep = SPEED_MPS * delta_sec\n",
    "        if dist_sep >= SAFE_DISTANCE_M:\n",
    "            continue\n",
    "        # otherwise conflict\n",
    "        return False\n",
    "    # opposite direction: no overlap of [entry_front, tail_clear] with any existing opposite intervals\n",
    "    opp_list = segment_occupancy[seg][-direction]\n",
    "    for (o1, o2) in opp_list:\n",
    "        if not (tail_clear <= o1 or entry_front >= o2):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def can_place_node(node, arrival_center, tail_clear):\n",
    "    # node busy interval for this train = [arrival_center, tail_clear + node_buffer]\n",
    "    buf = node_free_buffer(node)\n",
    "    busy_start = arrival_center\n",
    "    busy_end = tail_clear + timedelta(seconds=buf)\n",
    "    for (s,e) in node_occupancy[node]:\n",
    "        if not (busy_end <= s or busy_start >= e):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_segment_occupancy(seg, direction, entry_front, tail_clear):\n",
    "    segment_occupancy[seg][direction].append((entry_front, tail_clear))\n",
    "\n",
    "def add_node_occupancy(node, arrival_center, tail_clear):\n",
    "    buf = node_free_buffer(node)\n",
    "    node_occupancy[node].append((arrival_center, tail_clear + timedelta(seconds=buf)))\n",
    "\n",
    "# ----------------------------\n",
    "# Scheduling algorithm (greedy, round-robin over OD list until no new starts fit into 1 hour)\n",
    "# ----------------------------\n",
    "scheduled = []   # list of dicts: { 'od':(s,d), 'route': route_nodes, 'start_time': dt, 'edge_times': [ (u,v,entry_front, tail_clear, dir_sign) ] }\n",
    "\n",
    "# Precompute route edges lengths & durations for convenience\n",
    "route_infos = {}  # (s,d,idx) -> dict\n",
    "for key, rlist in feasible_routes.items():\n",
    "    s,d = key\n",
    "    for idx, path in enumerate(rlist):\n",
    "        edges = []\n",
    "        tot = 0.0\n",
    "        for i in range(len(path)-1):\n",
    "            u, v = path[i], path[i+1]\n",
    "            lm = G.edges[u, v]['length_m']\n",
    "            edges.append((u, v, lm))\n",
    "            tot += lm\n",
    "        route_infos[(s,d,idx)] = {'path': path, 'edges': edges, 'length_m': tot, 'durations': [lm / SPEED_MPS for (_,_,lm) in edges]}\n",
    "\n",
    "# helper to check & place a train on a given route starting at t0 (if feasible and start within window)\n",
    "def try_place_train(route_key, start_t0, allow_start_window_end):\n",
    "    info = route_infos[route_key]\n",
    "    edges = info['edges']\n",
    "    durations = info['durations']\n",
    "    # compute entry times & tail clears per segment, and arrival centers for nodes\n",
    "    times = []  # (u,v, entry_front, exit_front, tail_clear, dir_sign)\n",
    "    cur_t = start_t0\n",
    "    # also compute arrival_center times at nodes (front arrival)\n",
    "    node_arrivals = []\n",
    "    for idx, (u, v, lm) in enumerate(edges):\n",
    "        # direction canonical\n",
    "        seg = canonical_seg(u, v)\n",
    "        # compute direction sign relative to canonical\n",
    "        dir_sign = +1 if (u == seg[0] and v == seg[1]) else -1\n",
    "        entry_front = cur_t\n",
    "        travel_sec = durations[idx]\n",
    "        exit_front = entry_front + timedelta(seconds=travel_sec)\n",
    "        tail_clear = exit_front + timedelta(seconds=(TRAIN_LENGTH_M / SPEED_MPS))\n",
    "        times.append((u, v, entry_front, exit_front, tail_clear, dir_sign))\n",
    "        # arrival center to next node is exit_front (front reaches next node center)\n",
    "        node_arrivals.append((v, exit_front, tail_clear))  # node v arrival on exiting this segment\n",
    "        cur_t = exit_front\n",
    "    # node arrival for first node (source): front is at source at start_t0\n",
    "    source_node = info['path'][0]\n",
    "    source_tail_clear = start_t0 + timedelta(seconds=(TRAIN_LENGTH_M / SPEED_MPS))\n",
    "    # Will need to check source node occupancy as well (source arrival = start_t0)\n",
    "    # Now check constraints on segments and nodes\n",
    "    # first check source node\n",
    "    if not can_place_node(source_node, start_t0, source_tail_clear):\n",
    "        return False, None\n",
    "    # check segments sequentially\n",
    "    for (u, v, entry_front, exit_front, tail_clear, dir_sign) in times:\n",
    "        seg = canonical_seg(u, v)\n",
    "        # enforce starting window: entry_front must be <= allow_start_window_end if this is first segment\n",
    "        if entry_front > allow_start_window_end and (u == info['path'][0]):\n",
    "            return False, None\n",
    "        if not can_place_segment(seg, dir_sign, entry_front, tail_clear):\n",
    "            return False, None\n",
    "    # check nodes: source handled already; now intermediate nodes from node_arrivals\n",
    "    for (node, arrival_center, tail_clear) in node_arrivals:\n",
    "        if not can_place_node(node, arrival_center, tail_clear):\n",
    "            return False, None\n",
    "    # If all checks passed, reserve all segments and nodes\n",
    "    # Add source node occupancy\n",
    "    add_node_occupancy(source_node, start_t0, source_tail_clear)\n",
    "    # add segment and node occupancy\n",
    "    for (u, v, entry_front, exit_front, tail_clear, dir_sign) in times:\n",
    "        seg = canonical_seg(u, v)\n",
    "        add_segment_occupancy(seg, dir_sign, entry_front, tail_clear)\n",
    "    for (node, arrival_center, tail_clear) in node_arrivals:\n",
    "        add_node_occupancy(node, arrival_center, tail_clear)\n",
    "    # build compact edge_times list to store in schedule\n",
    "    edge_times = [(u, v, entry_front, tail_clear, dir_sign) for (u, v, entry_front, exit_front, tail_clear, dir_sign) in times]\n",
    "    return True, edge_times\n",
    "\n",
    "# round-robin scheduling until no new train placed in a full cycle\n",
    "start_window_end = START_TIME + timedelta(seconds=START_WINDOW_SECONDS)\n",
    "od_index = 0\n",
    "no_progress_rounds = 0\n",
    "max_no_progress = len(od_list) if len(od_list) > 0 else 1\n",
    "# To distribute start times, we'll attempt earliest-start (from START_TIME) for each try,\n",
    "# scanning start_t0 in 60s steps up to start_window_end.\n",
    "time_step = timedelta(seconds=60)\n",
    "\n",
    "# Create a list of all (od, route_idx) combinations sorted by route length (prefer short)\n",
    "od_route_keys = []\n",
    "for od in od_list:\n",
    "    s,d = od\n",
    "    for idx in range(len(feasible_routes[(s,d)])):\n",
    "        od_route_keys.append((s,d,idx))\n",
    "# sort by length\n",
    "od_route_keys.sort(key=lambda k: route_infos[k]['length_m'])\n",
    "\n",
    "# We'll greedy attempt to place as many trains as possible by repeatedly scanning od_route_keys\n",
    "placed_any = True\n",
    "while placed_any and len(scheduled) < MAX_TRAINS_CAP:\n",
    "    placed_any = False\n",
    "    for route_key in od_route_keys:\n",
    "        if len(scheduled) >= MAX_TRAINS_CAP:\n",
    "            break\n",
    "        s,d,idx = route_key\n",
    "        # try to place one train on this route at earliest possible start within window\n",
    "        t_try = START_TIME\n",
    "        placed = False\n",
    "        while t_try <= start_window_end:\n",
    "            ok, edge_times = try_place_train(route_key, t_try, start_window_end)\n",
    "            if ok:\n",
    "                scheduled.append({'od':(s,d), 'route': route_infos[route_key]['path'], 'start_time': t_try, 'edge_times': edge_times})\n",
    "                placed = True\n",
    "                placed_any = True\n",
    "                if DEBUG:\n",
    "                    print(f\"Placed train #{len(scheduled)} {s}->{d} start={t_try} route_hops={len(route_infos[route_key]['path'])} len={route_infos[route_key]['length_m']:.1f}m\")\n",
    "                break\n",
    "            t_try += time_step\n",
    "        # if not placed, move to next route_key\n",
    "    if DEBUG:\n",
    "        print(f\"Iteration complete: scheduled_count={len(scheduled)}\")\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Scheduling finished; total trains scheduled: {len(scheduled)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Build per-second occupancy log for animation & CSV\n",
    "# ----------------------------\n",
    "if not scheduled:\n",
    "    print(\"No trains scheduled. Exiting.\")\n",
    "    exit(0)\n",
    "\n",
    "# find sim end time (allow trains to finish even if they start in first hour)\n",
    "sim_end = START_TIME\n",
    "for tr in scheduled:\n",
    "    last_tail = max(et[3] for et in tr['edge_times'])\n",
    "    sim_end = max(sim_end, last_tail)\n",
    "total_seconds = int(max(1, (sim_end - START_TIME).total_seconds()))\n",
    "timestamps = [START_TIME + timedelta(seconds=i) for i in range(total_seconds+1)]\n",
    "\n",
    "# helper to get front position for a train at time t\n",
    "def train_front_position(train, t):\n",
    "    st = train['start_time']\n",
    "    if t < st:\n",
    "        return None\n",
    "    # if passed last tail clearing -> finished at last node\n",
    "    last_tail = max(et[3] for et in train['edge_times'])\n",
    "    if t >= last_tail:\n",
    "        last_node = train['route'][-1]\n",
    "        return (G.nodes[last_node]['x'], G.nodes[last_node]['y'], 'finished', None, None, None)\n",
    "    # find current edge where entry <= t <= tail_clear\n",
    "    for i, (u, v, entry_front, tail_clear, dir_sign) in enumerate(train['edge_times']):\n",
    "        # compute exit_front approx = entry_front + (length / speed)\n",
    "        length = next((lm for (uu,vv,lm) in route_infos[(train['od'][0],train['od'][1], 0)]['edges'] if (uu == u and vv == v) or (uu == v and vv == u)), None)\n",
    "        # the above tries to find the length in route_infos - but because route_infos keys used earlier may not match index 0 always,\n",
    "        # we instead fetch from train's route edges (we can map edges lengths from G)\n",
    "        # safer approach:\n",
    "        # find length from graph\n",
    "        length = G.edges[u, v]['length_m']\n",
    "        travel_sec = length / SPEED_MPS\n",
    "        exit_front = entry_front + timedelta(seconds=travel_sec)\n",
    "        if entry_front <= t <= tail_clear:\n",
    "            if t <= exit_front:\n",
    "                denom = (exit_front - entry_front).total_seconds()\n",
    "                frac = (t - entry_front).total_seconds() / denom if denom > 0 else 1.0\n",
    "            else:\n",
    "                frac = 1.0\n",
    "            x_u, y_u = G.nodes[u]['x'], G.nodes[u]['y']\n",
    "            x_v, y_v = G.nodes[v]['x'], G.nodes[v]['y']\n",
    "            x = x_u + (x_v - x_u) * frac\n",
    "            y = y_u + (y_v - y_u) * frac\n",
    "            return (x, y, 'moving', (u,v), entry_front, tail_clear)\n",
    "    return None\n",
    "\n",
    "# build records\n",
    "records = []\n",
    "for t in timestamps:\n",
    "    for idx, train in enumerate(scheduled, start=1):\n",
    "        meta = train_front_position(train, t)\n",
    "        if meta is None:\n",
    "            continue\n",
    "        x, y, state, edge_id, entry, exit = meta\n",
    "        records.append({\n",
    "            'timestamp': t.isoformat(),\n",
    "            'train_id': idx,\n",
    "            'x_m': x,\n",
    "            'y_m': y,\n",
    "            'node': train['route'][-1] if state == 'finished' else '',\n",
    "            'state': state,\n",
    "            'entry_time': entry.isoformat() if entry else '',\n",
    "            'exit_time': exit.isoformat() if exit else ''\n",
    "        })\n",
    "\n",
    "# write occupancy CSV\n",
    "fieldnames = ['timestamp','train_id','x_m','y_m','node','state','entry_time','exit_time']\n",
    "with open(OUT_OCC, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for r in records:\n",
    "        writer.writerow(r)\n",
    "if DEBUG:\n",
    "    print(f\"Wrote occupancy log to {OUT_OCC} (records: {len(records)})\")\n",
    "\n",
    "print(f\"Maximum number of trains scheduled safely (within 1 hour starts): {len(scheduled)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare animation (compress sim timeline to playback duration)\n",
    "# ----------------------------\n",
    "# plotting coordinates are original x,y\n",
    "x_vals = [G.nodes[n]['x'] for n in G.nodes]\n",
    "y_vals = [G.nodes[n]['y'] for n in G.nodes]\n",
    "xmin, xmax = min(x_vals), max(x_vals)\n",
    "ymin, ymax = min(y_vals), max(y_vals)\n",
    "xpad = max(1.0, 0.05 * (xmax - xmin + 1.0))\n",
    "ypad = max(1.0, 0.05 * (ymax - ymin + 1.0))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.set_xlim(xmin - xpad, xmax + xpad)\n",
    "ax.set_ylim(ymin - ypad, ymax + ypad)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title(\"Scheduled Trains Animation\")\n",
    "\n",
    "# draw network\n",
    "pos = {n:(G.nodes[n]['x'], G.nodes[n]['y']) for n in G.nodes}\n",
    "nx.draw_networkx_nodes(G, pos=pos, node_size=80, node_color='lightgray', ax=ax)\n",
    "nx.draw_networkx_edges(G, pos=pos, ax=ax, edge_color='gray')\n",
    "nx.draw_networkx_labels(G, pos=pos, font_size=8, ax=ax)\n",
    "\n",
    "# build frames\n",
    "FRAMES = int(ANIM_DURATION_SECONDS * FPS)\n",
    "INTERVAL_MS = int(1000 / FPS)\n",
    "\n",
    "sim_start = timestamps[0]\n",
    "sim_end_dt = timestamps[-1]\n",
    "sim_total_seconds = (sim_end_dt - sim_start).total_seconds() if sim_end_dt > sim_start else 1.0\n",
    "frame_sim_times = [sim_start + timedelta(seconds=(i/(FRAMES-1)) * sim_total_seconds) for i in range(FRAMES)]\n",
    "\n",
    "# index records by second for quick lookup\n",
    "records_by_dt = defaultdict(list)\n",
    "for r in records:\n",
    "    dt = datetime.fromisoformat(r['timestamp']).replace(microsecond=0)\n",
    "    records_by_dt[dt].append(r)\n",
    "\n",
    "def find_frame_records(sim_t):\n",
    "    k = sim_t.replace(microsecond=0)\n",
    "    if k in records_by_dt:\n",
    "        return records_by_dt[k]\n",
    "    # fallback +/-1s\n",
    "    for d in (k - timedelta(seconds=1), k + timedelta(seconds=1)):\n",
    "        if d in records_by_dt:\n",
    "            return records_by_dt[d]\n",
    "    return []\n",
    "\n",
    "# assign colors to trains\n",
    "train_ids = sorted({r['train_id'] for r in records})\n",
    "cmap = plt.get_cmap('tab20', max(1, len(train_ids)))\n",
    "train_colors = {tid: cmap(i % max(1, len(train_ids))) for i, tid in enumerate(train_ids)}\n",
    "\n",
    "scatter = ax.scatter([], [], s=100, zorder=5)\n",
    "labels = {tid: ax.text(0,0,\"\", fontsize=8, weight='bold') for tid in train_ids}\n",
    "\n",
    "def update(frame_idx):\n",
    "    sim_t = frame_sim_times[frame_idx]\n",
    "    recs = find_frame_records(sim_t)\n",
    "    pts = []\n",
    "    cols = []\n",
    "    # clear labels\n",
    "    for lab in labels.values():\n",
    "        lab.set_text(\"\")\n",
    "    for r in recs:\n",
    "        x = float(r['x_m']); y = float(r['y_m']); tid = r['train_id']\n",
    "        pts.append((x,y)); cols.append(train_colors[tid])\n",
    "        labels[tid].set_position((x + 0.5, y + 0.5))\n",
    "        labels[tid].set_text(str(tid))\n",
    "        labels[tid].set_color(train_colors[tid])\n",
    "    if pts:\n",
    "        scatter.set_offsets(np.array(pts))\n",
    "        scatter.set_color(cols)\n",
    "    else:\n",
    "        scatter.set_offsets(np.empty((0,2)))\n",
    "        scatter.set_color([])\n",
    "    ax.set_title(f\"Simulation @ {sim_t.strftime('%Y-%m-%d %H:%M:%S')}   Scheduled: {len(scheduled)}\")\n",
    "    return (scatter, *labels.values())\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=FRAMES, interval=INTERVAL_MS, blit=False, repeat=False)\n",
    "\n",
    "# Try to save MP4 first (requires ffmpeg). If fails, save GIF (Pillow).\n",
    "saved = False\n",
    "try:\n",
    "    print(\"Saving animation to MP4 (this may take a moment)...\")\n",
    "    ani.save(OUT_ANIM_MP4, fps=FPS, dpi=150)\n",
    "    print(f\"Saved MP4 to {OUT_ANIM_MP4}\")\n",
    "    saved = True\n",
    "except Exception as e:\n",
    "    print(\"MP4 save failed:\", str(e))\n",
    "    try:\n",
    "        print(\"Saving animation to GIF (fallback)...\")\n",
    "        ani.save(OUT_ANIM_GIF, fps=FPS, dpi=100)\n",
    "        print(f\"Saved GIF to {OUT_ANIM_GIF}\")\n",
    "        saved = True\n",
    "    except Exception as e2:\n",
    "        print(\"GIF save failed:\", str(e2))\n",
    "        print(\"Animation will still be shown interactively (if running in environment that supports it).\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
